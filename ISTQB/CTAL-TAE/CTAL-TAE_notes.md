# Notes CTAL-TAE - Test Automation Engineering

## 0.3 Ressources

| Ressource | Description |
|-----------|-------------|
| [ISTQB TEST AUTOMATION ENGINEER V2.0 (2025)](https://www.youtube.com/playlist?list=PLj5VKaW115t2z4bsJDcPJRJwKEQpv1QNF) | Playlist de vid√©os youtube de cours |
| [ISTQB CTAL-TAE Syllabus v2.0](https://www.istqb.org/sdm_downloads/istqb_ctal-tae_syllabus_v2-0/) | Syllabus de la certification |

## 0.4 Objectifs m√©tier

Cette section √©num√®re les objectifs m√©tier attendus d'un candidat ayant obtenu la certification en Automatisation des tests - Ing√©nierie.

### **Comp√©tences acquises apr√®s certification**

Un candidat ayant obtenu la certification en Automatisation des tests peut :

| Code | Objectif m√©tier |
|------|-----------------|
| **TAE-B01** | D√©crire l'objectif de l'Automatisation des tests |
| **TAE-B02** | Comprendre l'Automatisation des tests √† travers le cycle de vie du d√©veloppement logiciel |
| **TAE-B03** | Comprendre la configuration d'une infrastructure pour permettre l'Automatisation des tests |
| **TAE-B04** | Apprendre le processus d'√©valuation pour s√©lectionner les bons outils et les bonnes strat√©gies |
| **TAE-B05** | Comprendre les pr√©ceptes de conception pour concevoir des solutions d'Automatisation des tests modulaires et √©volutives |
| **TAE-B06** | Choisir une approche, y compris un pilote, pour planifier le d√©ploiement de l'Automatisation des tests dans le cycle de vie du d√©veloppement logiciel |
| **TAE-B07** | Concevoir et d√©velopper des solutions d'Automatisation des tests (nouvelles ou modifi√©es) qui r√©pondent aux besoins techniques |
| **TAE-B08** | Consid√©rer le p√©rim√®tre et l'approche de l'Automatisation des tests et de la maintenance des testware |
| **TAE-B09** | Comprendre comment les tests automatis√©s s'int√®grent dans les pipelines CI/CD |
| **TAE-B10** | Comprendre comment collecter, analyser et faire des rapports sur les donn√©es d'Automatisation des tests afin d'informer les parties prenantes |
| **TAE-B11** | V√©rifier l'infrastructure d'Automatisation des tests |
| **TAE-B12** | D√©finir les opportunit√©s d'am√©lioration continue pour l'Automatisation des tests |

### **Domaines de comp√©tences cl√©s**

- **Fondamentaux** : Objectifs et int√©gration dans le SDLC (TAE-B01, TAE-B02)
- **Infrastructure** : Configuration et v√©rification (TAE-B03, TAE-B11)
- **Strat√©gie** : √âvaluation d'outils et approches (TAE-B04, TAE-B06)
- **Conception** : Solutions modulaires et √©volutives (TAE-B05, TAE-B07)
- **Maintenance** : P√©rim√®tre et testware (TAE-B08)
- **Int√©gration** : Pipelines CI/CD (TAE-B09)
- **Reporting** : Collecte et analyse de donn√©es (TAE-B10)
- **Am√©lioration** : Processus d'am√©lioration continue (TAE-B12)

## 0.5 Objectifs d'apprentissage examinables et niveau cognitif

Les objectifs d'apprentissage soutiennent les objectifs m√©tier et sont utilis√©s pour cr√©er les examens de Testeur certifi√© Automatisation des tests - Ing√©nierie.

### **Niveaux cognitifs**

En g√©n√©ral, tous les contenus de ce syllabus sont examinables aux niveaux K2, K3 et K4, √† l'exception de l'Introduction et des Annexes.

- **K2 : Comprendre** - Reconna√Ætre, m√©moriser ou rappeler un concept
- **K3 : Appliquer** - Utiliser une proc√©dure dans une situation donn√©e
- **K4 : Analyser** - D√©composer en √©l√©ments constitutifs et d√©terminer les relations

### **Mots-cl√©s**

Tous les termes list√©s comme mots-cl√©s sous les titres de chapitres doivent √™tre retenus, m√™me s'ils ne sont pas explicitement mentionn√©s dans les objectifs d'apprentissage.

## 0.11 Organisation du syllabus

Il y a huit chapitres dont le contenu peut faire l'objet d'un examen. Le syllabus exige un minimum de **21 heures d'enseignement**.

### **Tableau des chapitres et comp√©tences**

| Chapitre | Titre | Dur√©e | Niveau | Comp√©tences vis√©es |
|----------|-------|-------|--------|-------------------|
| **1** | Introduction et objectifs | 45 min | K2 | Avantages/limites, int√©gration SDLC, s√©lection d'outils |
| **2** | Se pr√©parer √† l'Automatisation | 180 min | K4 | Configuration infrastructure, √©valuation SUT, recommandations techniques |
| **3** | Architecture d'Automatisation | 210 min | K3 | Conception gTAA, frameworks en couches, principes et patterns |
| **4** | Impl√©mentation | 150 min | K4 | D√©ploiement pilote, gestion des risques, maintenabilit√© |
| **5** | Strat√©gies d'impl√©mentation | 90 min | K3 | Int√©gration CI/CD, gestion configuration, d√©pendances API |
| **6** | Reporting et m√©triques | 150 min | K4 | Collecte de donn√©es, analyse des r√©sultats, rapports d'avancement |
| **7** | V√©rification de la solution | 135 min | K3 | V√©rification environnement, comportement scripts, analyse statique |
| **8** | Am√©lioration continue | 210 min | K4 | Opportunit√©s d'am√©lioration, recommandations, restructuration testware |

## Chapitre 1 : Introduction et objectifs de l'Automatisation des tests (45 minutes - K2)

### **Mots-cl√©s**

| **Mot** | **D√©finition** |
|---------------|-----------------|
| **syst√®me sous test** | Syst√®me qui est test√© pour un fonctionnement correct. Selon ISTQB, il s'agit de l'objet de test. |
| **Automatisation des tests** | Utilisation de logiciels pour effectuer ou soutenir les activit√©s de test, par exemple la gestion des tests, la conception des tests, l'ex√©cution des tests et la v√©rification des r√©sultats. |
| **ing√©nieur en Automatisation des tests** | Professionnel sp√©cialis√© dans la conception, le d√©veloppement et la maintenance de solutions d'automatisation des tests. |

### 1.1 Objectif de l'Automatisation des tests

#### **TAE-1.1.1 (K2)** : Expliquer les avantages et les inconv√©nients de l'Automatisation des tests

L'Automatisation des tests comprend :
- l'**utilisation d'outils logiciels** pour contr√¥ler et mettre en place des suites de tests,
- l'**ex√©cution automatis√©e** des tests,
- la **comparaison automatique** des r√©sultats r√©els aux r√©sultats attendus.

Cette approche couvre divers types de SUT (System avec/sans UI, applications mobiles, protocoles r√©seau) et va au-del√† des simples "frameworks" pour constituer un √©cosyst√®me complet d'outils incluant l'√©tablissement automatis√© de rapports.

| **AVANTAGES** | **Description** | **Exemple concret** |
|---------------|-----------------|-------------------|
| **Plus de tests par build** | Ex√©cution massive automatis√©e | 5000 tests vs 50 manuels |
| **Tests impossibles manuellement** | Capacit√©s d√©passant l'humain | Tests temps r√©el <1ms, 10k utilisateurs simultan√©s |
| **Tests plus complexes** | Sc√©narios sophistiqu√©s | Int√©gration multi-syst√®mes |
| **Rapidit√© d'ex√©cution** | Vitesse sup√©rieure | 2h vs 40h pour r√©gression |
| **R√©duction erreurs humaines** | √âlimination variations manuelles | Saisie 1000 jeux de donn√©es sans erreur |
| **Efficience des ressources** | Optimisation temps/co√ªt/personnel | 1 TAE remplace 5 testeurs manuels |
| **Feedback rapide** | Retour imm√©diat sur qualit√© | R√©sultats en temps r√©el |
| **Am√©lioration fiabilit√©** | Disponibilit√© et r√©cup√©ration | Tests de robustesse continus |
| **Coh√©rence d'ex√©cution** | Standardisation des tests | M√™me s√©quence √† chaque fois |

| **INCONV√âNIENTS** | **Description** | **Impact** |
|-------------------|-----------------|------------|
| **Co√ªts suppl√©mentaires** | TAE, mat√©riel, formation | Investissement initial √©lev√© |
| **Temps d√©veloppement** | Cr√©ation et maintenance | ROI diff√©r√© |
| **Objectifs clairs requis** | D√©finition pr√©cise n√©cessaire | Risque d'√©chec si flou |
| **Rigidit√© des tests** | Moins d'adaptabilit√© | Maintenance lors changements SUT |
| **D√©fauts suppl√©mentaires** | Bugs dans l'automatisation | Faux positifs/n√©gatifs |

| **LIMITES** | **Description** | **Exemples** |
|-------------|-----------------|--------------|
| **Automatisation partielle** | Tous tests manuels non automatisables | Tests exploratoires, utilisabilit√© |
| **Port√©e limit√©e** | Ne v√©rifie que ce pour quoi programm√© | Pas de d√©couverte fortuite |
| **Oracle machine uniquement** | R√©sultats interpr√©tables par machine | Pas d'√©valuation esth√©tique/ergonomique |
| **Caract√©ristiques qualit√©** | Certains aspects non testables | Intuitivit√©, ressenti utilisateur |

#### **Analyse comparative des co√ªts**

L'√©volution des co√ªts entre tests manuels et automatisation suit des trajectoires oppos√©es selon la complexit√© et la dur√©e de vie du syst√®me :

```mermaid
xychart-beta
    title "√âvolution des co√ªts : Tests Manuels vs Automatisation"
    x-axis "Projet" 0 --> 4
    y-axis "Co√ªt" 0 --> 4
    line "Tests Manuels" [0, 0.05, 0.08, 0.1, 0.12, 0.15, 0.18, 0.2, 0.22, 0.25, 0.28, 0.3, 0.32, 0.35, 0.38, 0.4, 0.45, 0.5, 0.6, 0.8, 1.2, 2.0, 3.5, 6.2]
    line "Automatisation" [0, 0.5, 0.8, 1.0, 1.2, 1.35, 1.48, 1.58, 1.67, 1.75, 1.82, 1.88, 1.93, 1.98, 2.02, 2.06, 2.09, 2.12, 2.15, 2.17, 2.19, 2.21, 2.23, 2.24, 2.25, 2.26, 2.27, 2.28]
```

### 1.2 L'Automatisation des tests dans le cycle de vie du d√©veloppement logiciel

#### **TAE-1.2.1 (K2)** : Expliquer comment l'Automatisation des tests est appliqu√©e dans les diff√©rents mod√®les de cycle de vie du d√©veloppement logiciel


L'impl√©mentation de l'automatisation varie selon le mod√®le SDLC utilis√©. Chaque approche pr√©sente des caract√©ristiques sp√©cifiques qui influencent la strat√©gie d'automatisation :

| **Mod√®le SDLC** | **Caract√©ristiques cl√©s** | **Impl√©mentation TA** | **Ex√©cution TA** |
|-----------------|----------------------|----------------------------------|------------------------|
| **Cascade** | ‚Ä¢ Mod√®le lin√©aire et s√©quentiel<br>‚Ä¢ Phases distinctes (exigences, conception, impl√©mentation, v√©rification, maintenance)<br>‚Ä¢ Documentation approuv√©e √† chaque phase<br>‚Ä¢ Processus rigide, changements co√ªteux | En parall√®le ou apr√®s la phase d'impl√©mentation | Phase de v√©rification uniquement |
| **Mod√®le en V** | ‚Ä¢ Mod√®le s√©quentiel<br>‚Ä¢ construit par niveau d'exigence (haut -> bas)<br>‚Ä¢ Activit√©s de test validant chaque niveau (composant, int√©gration, syst√®me, int√©gration syst√®me, acceptation) | TAF sp√©cifique pour chaque niveau | √Ä chaque niveau |
| **Agile** | ‚Ä¢ Possibilit√©s d'automatisation innombrables<br>‚Ä¢ Planification d√©cid√©e par TAE + repr√©sentants m√©tier<br>‚Ä¢ Pas de silos (d√©veloppeurs, testeurs, BA, etc. travaillent ensemble. Ex : revues code, programmation bin√¥me)<br>‚Ä¢ Automatisation in-sprint | Int√©gr√©e dans chaque sprint<br>Couverture tous niveaux de test | Ex√©cutions (int√©gration, acceptation, r√©gression) √† chaque sprint |


#### **TAE-1.2.2 (K2)** : S√©lectionner les outils d'Automatisation des tests appropri√©s pour un syst√®me sous test donn√©

Afin de s√©lectionner des outils adapt√©s, le TAE doit prendre en compte plusieurs facteurs critiques :

**Contraintes techniques des outils :**
- Sp√©cificit√© langage/plateforme (ex: Java, .NET, Python)
- Comp√©tences requises (frameworks, APIs, scripting)
- Champ d'application limit√© (performance ‚â† r√©gression)
- Effort d'int√©gration variable (Open Source vs Commercial)

**Adaptation au contexte projet :**
L'√©valuation doit consid√©rer les contraintes projet (technologies, budget, objectifs) et l'expertise de l'√©quipe. Une √©quipe sans connaissances programmation privil√©giera des solutions "low-code/no-code", tandis qu'une √©quipe technique b√©n√©ficiera d'outils align√©s avec le langage du SUT pour faciliter collaboration d√©veloppeurs-testeurs (d√©bogage des tests, cross-training, etc.).

La s√©lection d'outils d'automatisation appropri√©s n√©cessite une analyse multicrit√®res du contexte projet et technique :

| **Crit√®re d'analyse** | **Questions cl√©s** | **Impact sur choix outil** |
|-----------------------|-------------------|---------------------------|
| **Nature du SUT** | Type de syst√®me (web, mobile, API, desktop) ?<br>Technologies/langages utilis√©s ?<br>Contraintes techniques sp√©cifiques ? | Compatibilit√© langage/plateforme<br>Outils sp√©cialis√©s requis |
| **Besoins et contraintes projet** | Objectifs m√©tier et timeline ?<br>Budget disponible ?<br>Types de tests requis ? | Champ d'application outil<br>Performance vs r√©gression |
| **Taille √©quipe** | Nombre et disponibilit√© des testeurs ?<br>Exp√©riences et expertises ? | Licences et infrastructure<br>Formation n√©cessaire |
| **Expertise √©quipe** | Niveau technique des testeurs ?<br>Connaissances programmation ?<br>Exp√©rience frameworks ? | **Low-code/no-code** si peu technique<br>**Langage SUT** si technique |
| **Co√ªt/Budget** | Budget acquisition et maintenance ?<br>TCO long terme ?<br>ROI attendu ? | **Commercial** (cl√© en main)<br>**Open Source** (int√©gration lourde) |
| **Type de collaboration** | Travail avec d√©veloppeurs ?<br>Int√©gration CI/CD ?<br>D√©bogage partag√© ? | Outils communs pour collaboration<br>Formation crois√©e possible |


**Strat√©gies de s√©lection selon le contexte :**

**üéØ √âquipe peu technique :**
- Solutions "low-code/no-code" avec interface graphique
- Formation minimale requise, prise en main rapide
- R√©duction des comp√©tences programmation n√©cessaires

**üéØ √âquipe technique :**
- Outils align√©s avec le langage du SUT (Java, .NET, Python)
- Collaboration d√©veloppeurs-testeurs facilit√©e
- D√©bogage partag√© et formation crois√©e (cross-training)

**üéØ Contraintes budg√©taires :**
- **Commercial :** Solution cl√© en main, support inclus, co√ªt initial √©lev√©
- **Open Source :** Co√ªt licence faible, int√©gration plus lourde, maintenance interne

**üéØ Champ d'application :**
- Outils sp√©cialis√©s par type de test (performance ‚â† r√©gression ‚â† s√©curit√©)
- Compatibilit√© plateforme/technologie obligatoire
- √âvolutivit√© selon croissance projet

## Chapitre 2 : Se pr√©parer √† l'Automatisation des tests (180 minutes - K4)

### **Mots-cl√©s**

| **Mot** | **D√©finition** |
|---------------|-----------------|
| **Tests d'API** | Tests r√©alis√©s en soumettant des commandes au logiciel test√© via les interfaces de programmation de l'application directement. |
| **Tests de l'interface graphique** | Tests r√©alis√©s en interagissant avec le logiciel test√© via l'interface utilisateur graphique. |
| **Testabilit√©** | Degr√© d'efficacit√© et d'efficience avec lequel les crit√®res de test peuvent √™tre √©tablis pour un syst√®me et les tests peuvent √™tre effectu√©s. |

### 2.1 Comprendre la configuration d'une infrastructure permettant l'Automatisation des tests

#### **TAE-2.1.1 (K2)** : D√©crire les besoins de configuration d'une infrastructure permettant l'impl√©mentation de l'Automatisation des tests

La **testabilit√© du SUT** est une exigence non fonctionnelle critique qui doit √™tre con√ßue et impl√©ment√©e parall√®lement aux autres caract√©ristiques du syst√®me. Cette responsabilit√© incombe g√©n√©ralement √† l'architecte logiciel, souvent accompagn√© d'un TAE pour identifier les domaines d'am√©lioration sp√©cifiques.

**Solutions pour am√©liorer la testabilit√© :**

| **Solution** | **Description** | **Exemple d'impl√©mentation** |
|--------------|-----------------|------------------------------|
| **Identifiants d'accessibilit√©** | Attributs ou propri√©t√©s ajout√©s au code source permettant l'identification automatique des √©l√©ments pour les tests automatis√©s | `id="login-button"`, `data-testid="submit-form"`, `aria-label="search input"` |
| **Variables d'environnement syst√®me** | Param√®tres syst√®me configurables qui permettent d'adapter le comportement de l'application selon l'environnement de test | `DATABASE_URL=test-db:5432`, `API_ENDPOINT=https://test-api.com`, `LOG_LEVEL=DEBUG`, `FEATURE_FLAG_NEW_UI=true` |
| **Variables de d√©ploiement** | Param√®tres d√©finis avant le d√©ploiement pour configurer l'application selon l'environnement cible | Configuration de build, variables d'environnement CI/CD |

**Explications d√©taill√©es des solutions de testabilit√© :**

**üîç Identifiants d'accessibilit√© :**
- **Objectif** : Permettre aux outils d'automatisation de localiser et interagir avec les √©l√©ments de l'interface
- **Exemples concrets** :
  ```html
  <!-- HTML/Web -->
  <button id="submit-button" data-testid="login-submit">Connexion</button>
  <input aria-label="email input" data-testid="email-field" />
  
  <!-- Mobile (iOS) -->
  accessibilityIdentifier="loginButton"
  
  <!-- Mobile (Android) -->
  android:contentDescription="login button"
  ```

- **Impl√©mentation par framework** :
  ```javascript
  // Playwright
  await page.getByTestId('login-submit').click();
  await page.getByRole('button', { name: 'Connexion' }).click();
  await page.getByLabel('email input').fill('test@example.com');
  ```
  
  ```robot
  # Robot Framework
  Click Element    data-testid=login-submit
  Click Element    id=submit-button
  Input Text    aria-label=email input    test@example.com
  ```

**üîß Variables d'environnement syst√®me :**
- **Objectif** : Configurer dynamiquement l'application pour diff√©rents environnements de test
- **Exemples concrets** :
  ```bash
  # Base de donn√©es
  DATABASE_URL=postgresql://test:password@test-db:5432/testdb
  DATABASE_NAME=test_database
  
  # APIs et services
  API_BASE_URL=https://test-api.company.com
  PAYMENT_SERVICE_URL=https://test-payment.stripe.com
  
  # Configuration application
  LOG_LEVEL=DEBUG
  DEBUG_MODE=true
  FEATURE_FLAG_NEW_UI=true
  
  # S√©curit√©
  JWT_SECRET=test-secret-key
  ENCRYPTION_KEY=test-encryption-key
  ```

- **Impl√©mentation par framework** :
  ```javascript
  // Playwright - playwright.config.js
  module.exports = {
    use: {
      baseURL: process.env.BASE_URL || 'http://localhost:3000',
      timeout: parseInt(process.env.TIMEOUT) || 30000,
    },
    projects: [
      {
        name: 'test',
        use: { baseURL: process.env.TEST_API_URL }
      }
    ]
  };
  ```
  
  ```robot
  # Robot Framework - Variables
  *** Variables ***
  ${BROWSER}    %{BROWSER|chrome}
  ${BASE_URL}    %{BASE_URL|http://localhost:3000}
  ${TIMEOUT}    %{TIMEOUT|30s}
  ```

**üöÄ Variables de d√©ploiement :**
- **Objectif** : Configurer l'application au moment du d√©ploiement selon l'environnement cible
- **Exemples concrets** :
  ```yaml
  # Docker Compose
  environment:
    - NODE_ENV=test
    - PORT=3000
    - DATABASE_URL=${DATABASE_URL}
  
  # Kubernetes
  env:
    - name: ENVIRONMENT
      value: "test"
    - name: API_VERSION
      value: "v2"
  ```

**Aspects fondamentaux de la testabilit√© :**

| **Aspect** | **D√©finition** | **Impl√©mentation** |
|------------|----------------|-------------------|
| **Observabilit√©** | Capacit√© du SUT √† fournir des interfaces donnant un aper√ßu de son √©tat interne | Logs, m√©triques, APIs de monitoring, interfaces de d√©bogage |
| **Contr√¥labilit√©** | Capacit√© du SUT √† accepter des actions via des interfaces | √âl√©ments UI, appels de fonction, protocoles de communication (TCP/IP, USB) |
| **Transparence de l'architecture** | Documentation claire des composants et interfaces pour tous les niveaux de test | Architecture document√©e, interfaces bien d√©finies, composants modulaires |

#### **TAE-2.1.2 (K2)** : Expliquer comment l'Automatisation des tests est exploit√©e dans diff√©rents environnements

L'automatisation des tests s'adapte aux diff√©rents environnements selon les besoins sp√©cifiques de chaque phase du d√©veloppement. Ces environnements peuvent √™tre cr√©√©s via conteneurs, virtualisation ou autres approches techniques.

**Typologie des environnements de test :**

| **Environnement** | **Objectif principal** | **Types de tests** | **Caract√©ristiques** |
|-------------------|------------------------|-------------------|---------------------|
| **D√©veloppement local** | Cr√©ation initiale et test des composants | ‚Ä¢ Tests de composants<br>‚Ä¢ Tests GUI<br>‚Ä¢ Tests API<br>‚Ä¢ Tests bo√Æte blanche | IDE int√©gr√©, tests unitaires, d√©bogage direct |
| **Build** | Construction du logiciel et v√©rification de l'exactitude | ‚Ä¢ Tests de bas niveau<br>‚Ä¢ Tests d'int√©gration continue<br>‚Ä¢ Analyse statique | Agent CI/CD, pas de d√©ploiement r√©el |
| **Int√©gration** | Test du SUT enti√®rement int√©gr√© avec d'autres syst√®mes | ‚Ä¢ Tests d'interface utilisateur<br>‚Ä¢ Tests API<br>‚Ä¢ Tests d'int√©gration syst√®me<br>‚Ä¢ Tests d'acceptation | Monitoring pr√©sent, tests bo√Æte noire uniquement |
| **Pr√©production** | Audit des caract√©ristiques de qualit√© non fonctionnelles | ‚Ä¢ Tests de performance<br>‚Ä¢ Tests d'acceptation utilisateurs<br>‚Ä¢ Tests non fonctionnels | Ressemble √† la production, monitoring avanc√© |
| **Production/Exploitation** | √âvaluation en temps r√©el pendant l'utilisation | ‚Ä¢ Tests fonctionnels et non fonctionnels<br>‚Ä¢ Monitoring continu | Tests A/B, d√©ploiement canari, blue/green |

**Strat√©gies d'impl√©mentation par environnement :**

**üéØ Environnement de d√©veloppement :**
- Tests unitaires automatis√©s dans l'IDE
- Int√©gration continue locale
- Feedback imm√©diat pour les d√©veloppeurs

**üéØ Environnement de build :**
- Pipeline CI/CD automatis√©
- Tests de r√©gression rapides
- Validation de la qualit√© du code

**üéØ Environnement d'int√©gration :**
- Tests d'int√©gration complets
- Validation des interfaces entre syst√®mes
- D√©tection pr√©coce des probl√®mes d'int√©gration

**üéØ Environnement de pr√©production :**
- Tests de performance et charge
- Validation des exigences non fonctionnelles
- Simulation des conditions de production

**üéØ Environnement de production :**
- Monitoring continu et tests de surveillance
- Tests A/B pour validation des nouvelles fonctionnalit√©s
- D√©tection des probl√®mes en temps r√©el

### 2.2 Processus d'√©valuation pour s√©lectionner les bons outils et strat√©gies

#### **TAE-2.2.1 (K4)** : Analyser un syst√®me sous test pour d√©terminer la solution d'Automatisation des tests appropri√©e

L'analyse d'un SUT pour d√©terminer la TAS (Test Automation Solution) appropri√©e n√©cessite une approche structur√©e et collaborative. Le TAE doit rassembler les exigences en tenant compte du p√©rim√®tre et des capacit√©s du syst√®me.

**Facteurs d'analyse critique :**

| **Facteur** | **Questions cl√©s** | **Impact sur la TAS** |
|-------------|-------------------|----------------------|
| **Type d'application** | Web, mobile, desktop, API, service ? | Outils sp√©cialis√©s requis |
| **Technologies utilis√©es** | Langages, frameworks, plateformes ? | Compatibilit√© technique obligatoire |
| **Types de tests requis** | Fonctionnels, performance, s√©curit√©, API ? | Couverture d'outils n√©cessaire |
| **Niveaux de test** | Unitaires, int√©gration, syst√®me, acceptation ? | Architecture en couches |
| **R√¥les et comp√©tences** | D√©veloppeurs, testeurs, BA, DevOps ? | Formation et support requis |
| **P√©rim√®tre et dur√©e de vie** | Produit unique, ligne de produits, famille ? | √âvolutivit√© et maintenance |
| **Donn√©es de test** | Disponibilit√©, qualit√©, gestion ? | Strat√©gie de donn√©es |
| **Int√©grations tierces** | Applications externes, APIs, services ? | Strat√©gies de simulation |

**Exigences de la TAS :**

**üìã Activit√©s √† automatiser :**
- Gestion des tests (planification, suivi, reporting)
- Conception des tests (g√©n√©ration de cas de test)
- Ex√©cution des tests (automatisation des proc√©dures)
- V√©rification des r√©sultats (comparaison automatique)

**üìã Niveaux de test √† supporter :**
- Tests unitaires (d√©veloppement)
- Tests d'int√©gration (build)
- Tests syst√®me (int√©gration)
- Tests d'acceptation (pr√©production)

**üìã Types de tests √† supporter :**
- Tests fonctionnels (validation des fonctionnalit√©s)
- Tests non fonctionnels (performance, s√©curit√©)
- Tests d'API (validation des interfaces)
- Tests GUI (validation de l'interface utilisateur)

**üìã M√©thodes d'√©mulation :**
- Simulation d'applications tierces
- Mocking des services externes
- Stubbing des composants non disponibles
- Virtualisation des environnements

#### **TAE-2.2.2 (K4)** : Illustrer les constatations techniques d'une √©valuation d'outil

Apr√®s l'analyse du SUT et la collecte des exigences, l'√©valuation des outils n√©cessite une approche comparative structur√©e. Il est rare qu'un seul outil r√©ponde √† toutes les exigences, n√©cessitant souvent une combinaison d'outils.

**Crit√®res d'√©valuation des outils :**

| **Crit√®re** | **√âl√©ments d'√©valuation** | **Impact sur la d√©cision** |
|-------------|---------------------------|---------------------------|
| **Langage/Technologie** | Compatibilit√© avec le SUT, IDE support√© | Alignement avec l'√©quipe technique |
| **Configuration** | Support multi-environnements, valeurs dynamiques/statiques | Flexibilit√© d'adaptation |
| **Gestion des donn√©es** | Int√©gration r√©f√©rentiel central, contr√¥le de versions | Tra√ßabilit√© et maintenance |
| **Sp√©cialisation** | Outils diff√©rents par type de test | Complexit√© d'int√©gration |
| **Reporting** | Fonctionnalit√©s de rapport, alignement projet | Communication avec parties prenantes |
| **Int√©gration** | CI/CD, suivi t√¢ches, gestion tests, autres outils | √âcosyst√®me technique |
| **√âvolutivit√©** | Maintenabilit√©, facilit√© modification, compatibilit√©, fiabilit√© | Viabilit√© long terme |

**Tableau comparatif d'√©valuation :**

```markdown
| Exigence | Outil A | Outil B | Outil C | Priorit√© |
|----------|---------|---------|---------|----------|
| Compatibilit√© Java | ‚úÖ | ‚ö†Ô∏è | ‚ùå | Haute |
| Tests API | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | Haute |
| Int√©gration CI/CD | ‚úÖ | ‚úÖ | ‚úÖ | Moyenne |
| Co√ªt licence | ‚ùå | ‚úÖ | ‚úÖ | Moyenne |
| Formation requise | ‚ö†Ô∏è | ‚úÖ | ‚ùå | Basse |
```

**Processus de d√©cision :**

**üéØ Phase 1 - √âvaluation technique :**
- Analyse des capacit√©s fonctionnelles
- Tests de preuve de concept
- Validation de la compatibilit√©

**üéØ Phase 2 - √âvaluation organisationnelle :**
- Analyse des co√ªts (acquisition, maintenance, formation)
- √âvaluation de l'impact sur les processus existants
- Validation de l'acceptation par les √©quipes

**üéØ Phase 3 - Recommandation :**
- Pr√©sentation des options aux parties prenantes
- Justification des choix techniques et business
- Plan d'impl√©mentation et de migration

**Facteurs de succ√®s de l'√©valuation :**

**‚úÖ Collaboration multi-parties prenantes :**
- Implication des testeurs manuels
- Participation des analystes m√©tier
- Consultation des √©quipes techniques

**‚úÖ Approche it√©rative :**
- √âvaluation progressive des outils
- Tests pilotes pour validation
- Ajustements bas√©s sur les retours

**‚úÖ Vision long terme :**
- Consid√©ration de l'√©volutivit√©
- √âvaluation des co√ªts de maintenance
- Planification de l'√©volution technologique

## Chapitre 3 : Architecture d'Automatisation des tests (210 minutes - K3)

### **Mots-cl√©s**
- d√©veloppement pilot√© par les comportements
- capture/rejeux
- tests g√©n√©riques d'Automatisation des tests
- architecture d'Automatisation des tests
- tests pilot√©s par les mots-cl√©s
- scripting lin√©aire
- tests bas√©s sur des mod√®les
- scripting structur√©
- couche d'adaptation des tests
- harnais de tests
- test pilot√© par les donn√©es
- √©tape de test
- solution d'Automatisation des tests
- d√©veloppement pilot√© par les tests
- script de test

### **Objectifs d'apprentissage**

#### 3.1 Concepts de conception utilis√©s dans l'Automatisation des tests
- **TAE-3.1.1 (K2)** : Expliquer les principales fonctionnalit√©s d'une architecture d'Automatisation des tests
- **TAE-3.1.2 (K2)** : Expliquer comment concevoir une solution d'Automatisation des tests
- **TAE-3.1.3 (K3)** : Appliquer la stratification des frameworks d'Automatisation des tests
- **TAE-3.1.4 (K3)** : Appliquer diff√©rentes approches pour l'automatisation des cas de test
- **TAE-3.1.5 (K3)** : Appliquer les principes et les mod√®les de conception dans l'Automatisation des tests

## Chapitre 4 : Impl√©mentation de l'Automatisation des tests (150 minutes - K4)

### **Mots-cl√©s**
- risque
- contexte de test

### **Objectifs d'apprentissage**

#### 4.1 D√©veloppement de l'Automatisation des tests
- **TAE-4.1.1 (K3)** : Appliquer des lignes directrices qui soutiennent des activit√©s efficaces d'Automatisation des tests en mati√®re de pilotage et de d√©ploiement

#### 4.2 Risques associ√©s au d√©veloppement de l'Automatisation des tests
- **TAE-4.2.1 (K4)** : Analyser les risques li√©s au d√©ploiement et planifier des strat√©gies d'att√©nuation des risques pour l'Automatisation des tests

#### 4.3 Maintenabilit√© de la solution d'Automatisation des tests
- **TAE-4.3.1 (K2)** : Expliquer quels sont les facteurs qui soutiennent et affectent la maintenabilit√© de la solution d'Automatisation des tests

## Chapitre 5 : Strat√©gies d'impl√©mentation et de d√©ploiement (90 minutes - K3)

### **Mots-cl√©s**
- test de contrat

### **Objectifs d'apprentissage**

#### 5.1 Int√©gration aux pipelines CI/CD
- **TAE-5.1.1 (K3)** : Appliquer l'Automatisation des tests √† diff√©rents niveaux de test dans les pipelines
- **TAE-5.1.2 (K2)** : Expliquer la gestion de configuration pour les testware
- **TAE-5.1.3 (K2)** : Expliquer les d√©pendances de l'Automatisation des tests pour une infrastructure API

## Chapitre 6 : Reporting et m√©triques (150 minutes - K4)

### **Mots-cl√©s**
- mesure
- m√©trique
- logging des tests
- rapport d'avancement des tests
- fin de test

### **Objectifs d'apprentissage**

#### 6.1 Collecte, analyse et reporting des donn√©es d'Automatisation des tests
- **TAE-6.1.1 (K3)** : Appliquer des m√©thodes de collecte de donn√©es √† partir de la solution d'Automatisation des tests et du syst√®me sous test
- **TAE-6.1.2 (K4)** : Analyser les donn√©es de la solution d'Automatisation des tests et du syst√®me sous test pour mieux comprendre les r√©sultats
- **TAE-6.1.3 (K2)** : Expliquer comment un rapport d'avancement des tests est construit et publi√©

## Chapitre 7 : V√©rifier la solution d'Automatisation des tests (135 minutes - K3)

### **Mots-cl√©s**
- analyse statique

### **Objectifs d'apprentissage**

#### 7.1 V√©rification de l'infrastructure d'Automatisation des tests
- **TAE-7.1.1 (K3)** : Planifier la v√©rification de l'environnement d'Automatisation des tests, y compris la configuration des outils de test
- **TAE-7.1.2 (K2)** : Expliquer le comportement correct pour un script de test automatis√© donn√© et/ou une suite de tests
- **TAE-7.1.3 (K2)** : Identifier les cas o√π l'Automatisation des tests produit des r√©sultats inattendus
- **TAE-7.1.4 (K2)** : Expliquer comment l'analyse statique peut contribuer √† la qualit√© du code d'Automatisation des tests

## Chapitre 8 : Am√©lioration continue (210 minutes - K4)

### **Mots-cl√©s**
- validation de sch√©ma
- histogramme de test

### **Objectifs d'apprentissage**

#### 8.1 Possibilit√©s d'am√©lioration continue de l'Automatisation des tests
- **TAE-8.1.1 (K3)** : D√©couvrir les opportunit√©s d'am√©lioration des cas de test par la collecte et l'analyse de donn√©es
- **TAE-8.1.2 (K4)** : Analyser les aspects techniques d'une solution d'Automatisation des tests d√©ploy√©e et fournir des recommandations d'am√©lioration
- **TAE-8.1.3 (K3)** : Restructurer le testware automatis√© pour l'aligner sur les mises √† jour du SUT
- **TAE-8.1.4 (K2)** : R√©sumer les opportunit√©s d'utilisation des outils d'Automatisation des tests
